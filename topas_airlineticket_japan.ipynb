{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import warnings\n",
        "import os \n",
        "import pendulum\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "from datetime import datetime, timedelta\n",
        "from functools import partial\n",
        "\n",
        "from google.cloud import bigquery, storage\n",
        "\n",
        "# from utils.gcp import (create_if_not_exist_google_storage, get_gcp_file_count,\n",
        "#                        get_gcp_total_size, upload_to_bucket,\n",
        "#                        validate_bucket_files)\n",
        "# from utils.slack import on_failure, on_success\n",
        "# from utils.util import make_directory\n",
        "\n",
        "# from airflow import DAG\n",
        "# from airflow.operators.dummy import DummyOperator\n",
        "# from airflow.operators.python import PythonOperator\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "pd.set_option('mode.chained_assignment',  None) \n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"****\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "## get JSON from API url\n",
        "\n",
        "def get_json(depart_date, depart, arrive):\n",
        "    \n",
        "    url1 = (\n",
        "        \"https://air.jejupass.com/air/agent/b2c/AIR/INT/AIRINTSCH0100100010.k1?\"\n",
        "        + \"initform=OW\"\n",
        "        + \"&initCnt=0\"\n",
        "        + \"&initMax=2\"\n",
        "        + \"&domintgubun=I\"\n",
        "        + \"&depdomintgbn=D\"\n",
        "        + \"&tasktype=B2C\"\n",
        "        + \"&servicecacheyn=Y\"\n",
        "        + \"&secrchType=FARE\"\n",
        "        + \"&maxprice=\"\n",
        "        + \"&availcount=250\"\n",
        "        + \"&preferaircd=\"\n",
        "        + \"&depctycd=\" + depart\n",
        "        + \"&depctycd=\"\n",
        "        + \"&depctycd=\"\n",
        "        + \"&depctycd=\"\n",
        "        + \"&depctynm=\"\n",
        "        + \"&depctynm=\"\n",
        "        + \"&depctynm=\"\n",
        "        + \"&depctynm=\"\n",
        "        + \"&arrctycd=\" + arrive\n",
        "        + \"&arrctycd=\"\n",
        "        + \"&arrctycd=\"\n",
        "        + \"&arrctycd=\"\n",
        "        + \"&arrctynm=\"\n",
        "        + \"&arrctynm=\"\n",
        "        + \"&arrctynm=\"\n",
        "        + \"&arrctynm=\"\n",
        "        + \"&depdt=\" + depart_date\n",
        "        + \"&depdt=\"\n",
        "        + \"&depdt=\"\n",
        "        + \"&depdt=\"\n",
        "        + \"&opencase=N\"\n",
        "        + \"&opencase=N\"\n",
        "        + \"&opencase=N\"\n",
        "        + \"&openday=\"\n",
        "        + \"&openday=\"\n",
        "        + \"&openday=\"\n",
        "        + \"&opendayNm=\"\n",
        "        + \"&opendayNm=\"\n",
        "        + \"&opendayNm=\"\n",
        "        + \"&nonstop=\"\n",
        "        + \"&adtcount=1\"\n",
        "        + \"&chdcount=0\"\n",
        "        + \"&infcount=0\"\n",
        "        + \"&cabinclass=Y\"\n",
        "        + \"&research=false\"\n",
        "        + \"&anywhereDate=\"\n",
        "        + \"&KSESID=air%3Ab2c%3ASELK138XF%3ASELK138XF%3A%3A00\"\n",
        "    )\n",
        "    url2 = \"https://air.jejupass.com/air/agent/b2c/AIR/INT/AIRINTSCH010010001001.k1jsn?servicecacheyn=Y&requestedfaretype=&KSESID=air%3Ab2c%3ASELK138XF%3ASELK138XF%3A%3A00\"\n",
        "\n",
        "    req = requests.Session()\n",
        "    session = req.get(url1)\n",
        "    session = session.cookies['JSESSIONID']\n",
        "    cookie = {\n",
        "        'JSESSIONID': session\n",
        "    }    \n",
        "\n",
        "    res = requests.get(url2, cookies = cookie)\n",
        "    json_data = res.json()\n",
        "\n",
        "    return json_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "## JSON parsing and get details\n",
        "\n",
        "def get_data(json_data):\n",
        "\n",
        "    ## Price info\n",
        "    price_df = pd.DataFrame()\n",
        "\n",
        "    price_list = list(json_data['totalResult']['itineraries'].keys())\n",
        "\n",
        "    for i in price_list:\n",
        "\n",
        "        df1 = pd.json_normalize(json_data['totalResult']['itineraries'][i])\n",
        "        df2 = pd.json_normalize(json_data['totalResult']['itineraries'][i]['fares'][0]['prices'])\n",
        "        df3 = pd.json_normalize(json_data['totalResult']['itineraries'][i]['fares'])\n",
        "        \n",
        "        df1 = df1[['id', 'airline', 'seat', 'via', 'routingIds']]\n",
        "        df2 = df2[['price', 'originPrice', 'fuel', 'tax', 'tasf', 'que', 'etc', 'total', 'discount']]\n",
        "        df3 = df3[['booking', 'cabin', 'cabinNm']]\n",
        "\n",
        "        price_merge = pd.concat([df1, df2, df3], axis =1 )\n",
        "\n",
        "        price_df = price_df.append(price_merge)\n",
        "\n",
        "    price_df = price_df.reset_index(drop = True)\n",
        "\n",
        "    ## routing info\n",
        "    routing_df = pd.DataFrame()\n",
        "\n",
        "    routing_list = list(json_data['totalResult']['routings'].keys())\n",
        "\n",
        "    for i in routing_list:\n",
        "\n",
        "        df = pd.json_normalize(json_data['totalResult']['routings'][i])\n",
        "        routing_df = routing_df.append(df)\n",
        "\n",
        "    routing_df = routing_df.reset_index(drop = True)\n",
        "\n",
        "    ## Time info\n",
        "    time_df = pd.DataFrame()\n",
        "\n",
        "    time_list = list(json_data['totalResult']['segments'])\n",
        "\n",
        "    for i in time_list:\n",
        "        df = pd.json_normalize(json_data['totalResult']['segments'][i])\n",
        "        time_df = time_df.append(df)\n",
        "        \n",
        "    time_df = time_df.reset_index(drop = True)\n",
        "\n",
        "    return price_df, routing_df, time_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "## data processing\n",
        "\n",
        "def data_processing(price_df, routing_df, time_df):\n",
        "\n",
        "    price_df = price_df.query(\"via == 0\") # Direct only\n",
        "    price_df = price_df.reset_index(drop = True)\n",
        "    for i in range(len(price_df)):\n",
        "        price_df.loc[i, ['routingIds', 'booking', 'cabin', 'cabinNm']] = price_df.loc[i, ['routingIds', 'booking', 'cabin', 'cabinNm']].apply(lambda x: ','.join(map(str, x)))\n",
        "        \n",
        "    routing_df['segmentIds'] = pd.DataFrame(routing_df['segmentIds'].tolist())[0]\n",
        "    routing_df = routing_df.drop(['via', 'fstamp', 'fminute', 'depTime', 'jtime', 'ctime', 'atime', 'flightDay', 'codeshare'], axis = 1)\n",
        "\n",
        "    time_df = time_df.drop(['airline', 'ctime', 'jtime', 'depTimestamp', 'arrTimestamp', 'fstamp', 'fminute', 'depTime', 'stopovers', 'srvlist'], axis = 1)\n",
        "\n",
        "    merge1 = pd.merge(price_df, routing_df, left_on = 'routingIds', right_on = 'id', how = 'left')\n",
        "    merge2 = pd.merge(merge1, time_df, left_on = 'segmentIds', right_on = 'id', how = 'left')\n",
        "\n",
        "    final_df = merge2.sort_values('total')\n",
        "    final_df = final_df.reset_index(drop = True)\n",
        "\n",
        "    final_df['depTime'] = final_df['depDate'].str.slice(8, 12)\n",
        "    final_df['depDate'] = final_df['depDate'].str.slice(0, 8)\n",
        "    final_df['arrTime'] = final_df['arrDate'].str.slice(8, 12)\n",
        "    final_df['arrDate'] = final_df['arrDate'].str.slice(0, 8)\n",
        "\n",
        "    final_df = final_df[[\n",
        "        'depDate'\n",
        "        , 'depTime'\n",
        "        , 'arrDate'\n",
        "        , 'arrTime'\n",
        "        , 'depCity'\n",
        "        , 'depCityNm'\n",
        "        , 'arrCity'\n",
        "        , 'arrCityNm'\n",
        "        , 'depAirport'\n",
        "        , 'depAirportNm'\n",
        "        , 'arrAirport'\n",
        "        , 'arrAirportNm'\n",
        "        # , 'discount' # ?\n",
        "        , 'airline'\n",
        "        , 'flightNo'\n",
        "        , 'equipment'\n",
        "        , 'equipmentNm'\n",
        "        , 'booking'\n",
        "        , 'cabin'\n",
        "        # , 'an' # ?\n",
        "        , 'seat'\n",
        "        , 'via'\n",
        "        , 'originPrice'\n",
        "        , 'price'\n",
        "        , 'fuel'\n",
        "        , 'tax'\n",
        "        , 'tasf'\n",
        "        , 'que'\n",
        "        , 'etc'\n",
        "        , 'total'\n",
        "        ]]\n",
        "\n",
        "    search_date = datetime.today().strftime('%Y%m%d')\n",
        "    final_df['searchDate'] = search_date\n",
        "    \n",
        "    final_df = final_df.reset_index(drop = True)\n",
        "    final_df = final_df.astype({\n",
        "        'depDate': 'string'\n",
        "        , 'depTime': 'string'\n",
        "        , 'arrDate': 'string'\n",
        "        , 'arrTime': 'string'\n",
        "        , 'depCity': 'string'\n",
        "        , 'depCityNm': 'string'\n",
        "        , 'arrCity': 'string'\n",
        "        , 'arrCityNm': 'string'\n",
        "        , 'depAirport': 'string'\n",
        "        , 'depAirportNm': 'string'\n",
        "        , 'arrAirport': 'string'\n",
        "        , 'arrAirportNm': 'string'\n",
        "        , 'airline': 'string'\n",
        "        , 'flightNo': 'string'\n",
        "        , 'equipment': 'string'\n",
        "        , 'equipmentNm': 'string'\n",
        "        , 'booking': 'string'\n",
        "        , 'cabin': 'string'\n",
        "        , 'seat': int\n",
        "        , 'via': int\n",
        "        , 'originPrice': int\n",
        "        , 'price': int\n",
        "        , 'fuel': int\n",
        "        , 'tax': int\n",
        "        , 'tasf': int\n",
        "        , 'que': int\n",
        "        , 'etc': int\n",
        "        , 'total': int\n",
        "        , 'searchDate': 'string'\n",
        "    })\n",
        "\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Main fuction\n",
        "\n",
        "def airline_ticket_japan():\n",
        "    \n",
        "    kor_airpot = ['SEL', 'CJU', 'PUS', 'CJJ', 'KWJ', 'TAE']\n",
        "    jap_airport = ['FUK', 'TYO', 'SPK', 'NGO', 'OKA', 'KIX']\n",
        "\n",
        "    air_route = []\n",
        "\n",
        "    for depart in kor_airpot:\n",
        "        for arrive in jap_airport:\n",
        "            air_route.append([depart, arrive])\n",
        "            air_route.append([arrive, depart])\n",
        "\n",
        "    final_df = pd.DataFrame()\n",
        "\n",
        "    for i in trange(1, 61):\n",
        "        date = datetime.today() + timedelta(i)\n",
        "        date = date.strftime('%Y-%m-%d')\n",
        "\n",
        "        for j in air_route:\n",
        "            depart = j[0]\n",
        "            arrive = j[1]\n",
        "\n",
        "            json_data = get_json(date, depart, arrive)\n",
        "\n",
        "            if json_data['totalResult']['criteria'] == None:\n",
        "                print(date, depart, arrive, \"is None\")\n",
        "                continue\n",
        "\n",
        "            # try\n",
        "            \n",
        "            price_df, routing_df, time_df = get_data(json_data)\n",
        "            total_df = data_processing(price_df, routing_df, time_df)\n",
        "\n",
        "            # file_name = f\"airline_japan_dep={depart}_arr={arrive}_depDate={date}.parquet\"\n",
        "            # env = \"prd\" # stg: 테스트\n",
        "            # root_directory = \"crawling_data/airline_japan\"\n",
        "            # try:\n",
        "            #     upload_to_bucket(total_df, file_name, env, root_directory)\n",
        "            # except Exception as e:\n",
        "            #     print(e)\n",
        "            #     print(\"Failed to upload to bucket\")\n",
        "\n",
        "            final_df = final_df.append(total_df)\n",
        "\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "kor_airpot = ['SEL', 'CJU', 'PUS', 'CJJ', 'KWJ', 'TAE']\n",
        "jap_airport = ['FUK', 'TYO', 'SPK', 'NGO', 'OKA', 'KIX']\n",
        "\n",
        "air_route = []\n",
        "\n",
        "for depart in kor_airpot:\n",
        "    for arrive in jap_airport:\n",
        "        air_route.append([depart, arrive])\n",
        "        air_route.append([arrive, depart])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-01-03 CJU NGO is None\n",
            "2023-01-03 KWJ NGO is None\n",
            "2023-01-03 TAE SPK is None\n",
            "2023-01-03 SPK TAE is None\n",
            "2023-01-03 TAE NGO is None\n",
            "2023-01-03 NGO TAE is None\n",
            "2023-01-03 TAE OKA is None\n",
            "2023-01-03 OKA TAE is None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [02:38<02:38, 158.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-01-04 TAE NGO is None\n",
            "2023-01-04 NGO TAE is None\n",
            "2023-01-04 OKA TAE is None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [05:15<00:00, 157.69s/it]\n"
          ]
        }
      ],
      "source": [
        "## Without Multithreading\n",
        "\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "for i in trange(1, 3):\n",
        "    date = datetime.today() + timedelta(i)\n",
        "    date = date.strftime('%Y-%m-%d')\n",
        "\n",
        "    for j in air_route:\n",
        "        depart = j[0]\n",
        "        arrive = j[1]\n",
        "\n",
        "        json_data = get_json(date, depart, arrive)\n",
        "\n",
        "        if json_data['totalResult']['criteria'] == None:\n",
        "            print(date, depart, arrive, \"is None\")\n",
        "            continue\n",
        "        \n",
        "        price_df, routing_df, time_df = get_data(json_data)\n",
        "        total_df = data_processing(price_df, routing_df, time_df)\n",
        "\n",
        "        final_df = final_df.append(total_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## With Multithreading\n",
        "\n",
        "def test(date, air_route):\n",
        "    final_df = pd.DataFrame()\n",
        "\n",
        "    for j in air_route:\n",
        "        depart = j[0]\n",
        "        arrive = j[1]\n",
        "\n",
        "        json_data = get_json(date, depart, arrive)\n",
        "\n",
        "        if json_data['totalResult']['criteria'] == None:\n",
        "            print(date, depart, arrive, \"is None\")\n",
        "            continue\n",
        "        \n",
        "        price_df, routing_df, time_df = get_data(json_data)\n",
        "        total_df = data_processing(price_df, routing_df, time_df)\n",
        "\n",
        "        final_df = final_df.append(total_df)\n",
        "\n",
        "    return final_df\n",
        "\n",
        "processes = []\n",
        "\n",
        "with ThreadPoolExecutor(max_workers = 10) as executor:\n",
        "    for i in trange(1, 3):\n",
        "        date = datetime.today() + timedelta(i)\n",
        "        date = date.strftime('%Y-%m-%d')\n",
        "\n",
        "        processes.append(executor.submit(test(date, air_route)))\n",
        "\n",
        "for task in as_completed(processes):\n",
        "    print(task.result())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import requests\n",
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# from time import time\n",
        "\n",
        "# url_list = [\n",
        "#     \"https://via.placeholder.com/400\",\n",
        "#     \"https://via.placeholder.com/410\",\n",
        "#     \"https://via.placeholder.com/420\",\n",
        "#     \"https://via.placeholder.com/430\",\n",
        "#     \"https://via.placeholder.com/440\",\n",
        "#     \"https://via.placeholder.com/450\",\n",
        "#     \"https://via.placeholder.com/460\",\n",
        "#     \"https://via.placeholder.com/470\",\n",
        "#     \"https://via.placeholder.com/480\",\n",
        "#     \"https://via.placeholder.com/490\",\n",
        "#     \"https://via.placeholder.com/500\",\n",
        "#     \"https://via.placeholder.com/510\",\n",
        "#     \"https://via.placeholder.com/520\",\n",
        "#     \"https://via.placeholder.com/530\",\n",
        "# ]\n",
        "\n",
        "# def download_file(url):\n",
        "#     html = requests.get(url, stream=True)\n",
        "#     return html.status_code\n",
        "\n",
        "# start = time()\n",
        "\n",
        "# processes = []\n",
        "\n",
        "# with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "#     for url in url_list:\n",
        "#         processes.append(executor.submit(download_file, url))\n",
        "\n",
        "# for task in as_completed(processes):\n",
        "#     print(task.result())\n",
        "\n",
        "\n",
        "# print(f'Time taken: {time() - start}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AIRFLOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# admin = [\"iwnoh\", \"ian\"]\n",
        "# local_tz = pendulum.timezone(\"Asia/Seoul\")\n",
        "# apply_env = \"prd\"  # \"dev\", \"stg\", \"prd\"\n",
        "# gcp_root_directory = \"crawling_data/airline_japan\"\n",
        "# use_columns = [\n",
        "#     'depDate',\n",
        "#     'depTime',\n",
        "#     'arrDate',\n",
        "#     'arrTime',\n",
        "#     'depCity',\n",
        "#     'depCityNm',\n",
        "#     'arrCity',\n",
        "#     'arrCityNm',\n",
        "#     'depAirport',\n",
        "#     'depAirportNm',\n",
        "#     'arrAirport',\n",
        "#     'arrAirportNm',\n",
        "#     'airline',\n",
        "#     'flightNo',\n",
        "#     'equipment',\n",
        "#     'equipmentNm',\n",
        "#     'booking',\n",
        "#     'cabin',\n",
        "#     'seat',\n",
        "#     'via',\n",
        "#     'originPrice',\n",
        "#     'price',\n",
        "#     'fuel',\n",
        "#     'tax',\n",
        "#     'tasf',\n",
        "#     'que',\n",
        "#     'etc',\n",
        "#     'total',\n",
        "#     'searchDate'\n",
        "#  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dag = DAG(\n",
        "#     dag_id = f\"crawling_to_google_storage_jejupass_airline_japan_dag_{apply_env}\",\n",
        "#     description = f\"{apply_env}_TOPAS 일본 항공권 데이터를 크롤링해서 GoogleStorage에 업로드한다.\",\n",
        "#     start_date = datetime(2022, 12, 27, tzinfo = local_tz),\n",
        "#     schedule_interval = \"0 6 * * *\",  #ㄴ schedule_interval은 start_date의 timezone을 따른다.\n",
        "#     tags = [\"air\", \"topas\", \"japan\", \"crawling\", \"google-storage\", apply_env] + admin,\n",
        "# )\n",
        "\n",
        "# preprocess_task = PythonOperator(\n",
        "#     task_id = \"create_if_not_exist_google_storage\",\n",
        "#     python_callable = create_if_not_exist_google_storage,\n",
        "#     op_kwargs = {\"env\": apply_env, \"root_directory\": gcp_root_directory},\n",
        "#     provide_context = True,\n",
        "#     dag = dag,\n",
        "#     on_failure_callback = partial(on_failure, admin = admin)\n",
        "# )\n",
        "\n",
        "# airline_japan_task = PythonOperator(\n",
        "#     task_id = \"airline_japan_task\",\n",
        "#     python_callable = airline_ticket_japan,\n",
        "#     op_kwargs = {\n",
        "#         \"env\": apply_env, \n",
        "#         \"root_directory\": gcp_root_directory, \n",
        "#         \"use_columns\": use_columns,\n",
        "#         \"execution_yyyymmdd_HHMM\": \"{{execution_date.in_timezone('Asia/Seoul').strftime('%Y%m%d_%H%M')}}\",\n",
        "#     },\n",
        "#     dag = dag,\n",
        "#     on_failure_callback = partial(on_failure, admin = admin)\n",
        "# )\n",
        "\n",
        "# validate_task = PythonOperator(\n",
        "#     task_id = \"validate_bucket_files\",\n",
        "#     python_callable = validate_bucket_files,\n",
        "#     op_kwargs = {\n",
        "#         \"env\": apply_env\n",
        "#         , \"root_directory\": gcp_root_directory},\n",
        "#     provide_context = True,\n",
        "#     dag = dag,\n",
        "#     on_failure_callback = partial(on_failure, admin = admin)\n",
        "# )\n",
        "\n",
        "# slack_alert_task = DummyOperator(\n",
        "#     task_id = \"send_to_slack_with_validates\",\n",
        "#     on_success_callback = partial(on_success, task_id = \"validate_bucket_files\"),\n",
        "#     dag=dag\n",
        "# )\n",
        "\n",
        "# preprocess_task >> airline_japan_task >> validate_task >> slack_alert_task"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.10.8 ('crawler')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "11502847fd950ebce76ad0272a4d8c93d6ce5f0384bb15423928750cbb4d1b2e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
